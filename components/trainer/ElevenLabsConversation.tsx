'use client'

import { useCallback, useEffect, useRef, useState } from 'react'
import { Conversation } from '@elevenlabs/client'

type ElevenLabsConversationProps = {
  agentId: string
  conversationToken: string
  autostart?: boolean
}

export default function ElevenLabsConversation({ agentId, conversationToken, autostart = true }: ElevenLabsConversationProps) {
  const conversationRef = useRef<any>(null)
  const [status, setStatus] = useState<'disconnected' | 'connecting' | 'connected' | 'error'>('disconnected')
  const [errorMessage, setErrorMessage] = useState<string>('')

  const dispatchStatus = (s: 'disconnected' | 'connecting' | 'connected' | 'error') => {
    window.dispatchEvent(new CustomEvent('connection:status', { detail: s === 'connected' ? 'connected' : s === 'connecting' ? 'connecting' : s === 'error' ? 'error' : 'idle' }))
  }

  const start = useCallback(async () => {
    console.log('ðŸŽ¬ start() called')
    console.log('ðŸŽŸï¸ conversationToken:', conversationToken ? conversationToken.substring(0, 30) + '...' : 'MISSING')
    console.log('ðŸ¤– agentId:', agentId)

    if (!agentId) {
      console.error('âŒ No agent ID provided')
      setErrorMessage('No agent ID provided')
      setStatus('error')
      dispatchStatus('error')
      return
    }

    if (!conversationToken) {
      console.error('âŒ No conversation token provided')
      setErrorMessage('No conversation token provided')
      setStatus('error')
      dispatchStatus('error')
      return
    }

    if (conversationRef.current) {
      console.log('âš ï¸ Conversation already exists, skipping')
      return
    }

    try {
      console.log('ðŸŽ¤ Requesting microphone permission...')
      await navigator.mediaDevices.getUserMedia({ audio: true })
      console.log('âœ… Microphone permission granted')

      setStatus('connecting')
      dispatchStatus('connecting')
      setErrorMessage('')

      console.log('ðŸš€ Calling Conversation.startSession with WebRTC...')
      
      const conversation = await Conversation.startSession({
        conversationToken,
        connectionType: 'webrtc',
        
        onConnect: () => {
          console.log('âœ… WebRTC Connected!')
          setStatus('connected')
          dispatchStatus('connected')
          setErrorMessage('')
        },
        
        onDisconnect: (reason?: any) => {
          console.log('ðŸ”Œ Disconnected:', reason)
          setStatus('disconnected')
          dispatchStatus('disconnected')
        },
        
        onModeChange: (mode: any) => {
          console.log('ðŸŽ¯ Mode changed:', mode)
          // Mode can be: 'speaking', 'listening', 'idle', etc.
          window.dispatchEvent(new CustomEvent('agent:mode', { detail: mode }))
        },
        
        onStatusChange: (status: any) => {
          console.log('ðŸ“Š Status changed:', status)
          window.dispatchEvent(new CustomEvent('agent:status', { detail: status }))
        },
        
        onMessage: (msg: any) => {
          console.log('ðŸ“¨ Message received:', JSON.stringify(msg, null, 2))
          window.dispatchEvent(new CustomEvent('agent:message', { detail: msg }))
          
          // Extract transcript text from various message formats
          const extractTranscripts = (message: any) => {
            let userText = ''
            let agentText = ''
            
            try {
              // Handle conversation_updated messages (WebRTC format)
              if (message?.type === 'conversation_updated') {
                const messages = message?.conversation?.messages || []
                if (messages.length > 0) {
                  const lastMsg = messages[messages.length - 1]
                  if (lastMsg?.role === 'user' && lastMsg?.content) {
                    userText = lastMsg.content
                  } else if (lastMsg?.role === 'assistant' && lastMsg?.content) {
                    agentText = lastMsg.content
                  }
                }
              }
              // Handle user_transcript messages
              else if (message?.type === 'user_transcript') {
                userText = typeof message.user_transcript === 'string' 
                  ? message.user_transcript 
                  : (message.user_transcript?.text || message.text || '')
              }
              // Handle agent_response messages
              else if (message?.type === 'agent_response') {
                const ar = message.agent_response
                if (typeof ar === 'string') {
                  agentText = ar
                } else if (ar?.text) {
                  agentText = ar.text
                } else if (ar?.content) {
                  agentText = ar.content
                } else if (Array.isArray(ar?.messages)) {
                  agentText = ar.messages.map((m: any) => m?.text).filter(Boolean).join(' ')
                }
              }
            } catch (e) {
              console.error('Error extracting transcripts:', e)
            }
            
            return { userText, agentText }
          }
          
          const { userText, agentText } = extractTranscripts(msg)
          
          if (userText) {
            console.log('ðŸ‘¤ User said:', userText)
            window.dispatchEvent(new CustomEvent('agent:user', { detail: userText }))
          }
          
          if (agentText) {
            console.log('ðŸ¤– Agent said:', agentText)
            window.dispatchEvent(new CustomEvent('agent:response', { detail: agentText }))
          }
          
          // Log other message types for debugging
          if (!userText && !agentText) {
            if (msg?.type === 'conversation_initiation_metadata') {
              console.log('ðŸŽ¬ Conversation initiated')
            } else if (msg?.type === 'interruption') {
              console.log('âœ‹ User interrupted agent')
            } else if (msg?.type === 'ping') {
              console.log('ðŸ“ Ping')
            } else if (msg?.type === 'audio') {
              console.log('ðŸ”Š Audio chunk')
            } else if (msg?.type) {
              console.log('â„¹ï¸  Message type:', msg.type)
            }
          }
        },
        
        onError: (err: any) => {
          console.error('âŒ WebRTC Error:', err)
          const errMsg = err?.message || err?.error || err?.detail || 'Connection error'
          setErrorMessage(errMsg)
          setStatus('error')
          dispatchStatus('error')
        },
      })

      conversationRef.current = conversation
      console.log('âœ… Conversation started successfully')
      console.log('ðŸ“‹ Conversation object type:', typeof conversation)
      console.log('ðŸ“‹ Conversation methods:', conversation ? Object.keys(conversation) : 'none')
      console.log('ðŸ” Checking conversation object for transcript methods...')
      console.log('ðŸ” Has getConversation?', typeof (conversation as any)?.getConversation === 'function')
      console.log('ðŸ” Has getId?', typeof (conversation as any)?.getId === 'function')
      console.log('ðŸ” Has getInputVolume?', typeof (conversation as any)?.getInputVolume === 'function')
      console.log('ðŸ” Has setVolume?', typeof (conversation as any)?.setVolume === 'function')
      
      // Try to get conversation ID to fetch transcripts
      if (typeof (conversation as any)?.getId === 'function') {
        try {
          const convId = await (conversation as any).getId()
          console.log('ðŸ†” Conversation ID:', convId)
          
          // Store it globally so we can fetch transcripts
          ;(window as any).elevenConversationId = convId
        } catch (e) {
          console.log('âš ï¸ Could not get conversation ID:', e)
        }
      }
      
    } catch (error: any) {
      console.error('âŒ Failed to start conversation:', error)
      const errMsg = error?.message || error?.error || 'Failed to connect'
      setErrorMessage(errMsg)
      setStatus('error')
      dispatchStatus('error')
    }
  }, [agentId, conversationToken])

  const stop = useCallback(async () => {
    try {
      if (conversationRef.current) {
        await conversationRef.current.endSession()
        conversationRef.current = null
      }
      setStatus('disconnected')
      dispatchStatus('disconnected')
    } catch (e) {
      console.error('âŒ Error ending conversation:', e)
    }
  }, [])

  useEffect(() => {
    if (autostart) {
      console.log('ðŸŽ¬ Autostart enabled, starting in 100ms...')
      const id = setTimeout(() => start(), 100)
      return () => clearTimeout(id)
    }
  }, [autostart, start])

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      if (conversationRef.current) {
        console.log('ðŸ§¹ Cleaning up conversation on unmount')
        conversationRef.current.endSession().catch(() => {})
      }
    }
  }, [])

  // This component is headless
  return null
}
